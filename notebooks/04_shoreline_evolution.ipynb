{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91b40e6",
   "metadata": {},
   "source": [
    "# Shoreline Evolution\n",
    "Notebook environment to migrate netcdf files to CF compliant zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aef40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional; code formatter, installed as jupyter lab extension\n",
    "#%load_ext lab_black\n",
    "# Optional; code formatter, installed as jupyter notebook extension\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f67518",
   "metadata": {},
   "source": [
    "### Configure OS independent paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy.ma as ma\n",
    "\n",
    "# Make root directories importable by appending root to path\n",
    "cwd = pathlib.Path().resolve()\n",
    "sys.path.append(os.path.dirname(cwd))\n",
    "\n",
    "# Get root paths\n",
    "home = pathlib.Path().home()\n",
    "root = home.root\n",
    "\n",
    "# Import custom functionality\n",
    "from etl import p_drive\n",
    "from etl.CF_compliancy_checker import check_compliancy, save_compliancy\n",
    "\n",
    "# Define (local and) remote drives\n",
    "coclico_data_dir = p_drive.joinpath(\"11205479-coclico\", \"data\")\n",
    "\n",
    "# Workaround to the Windows OS (10) udunits error after installation of cfchecker: https://github.com/SciTools/iris/issues/404\n",
    "os.environ[\"UDUNITS2_XML_PATH\"] = str(\n",
    "    home.joinpath(  # change to the udunits2.xml file dir in your Python installation\n",
    "        r\"Anaconda3\\pkgs\\udunits2-2.2.28-h892ecd3_0\\Library\\share\\udunits\\udunits2.xml\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef15534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project paths & files (manual input)\n",
    "ds_dir = coclico_data_dir.joinpath(\"04_shoreline_jrc\")\n",
    "ds_path = ds_dir.joinpath(\"globalCoastalMorphodynamicsDb.nc\")\n",
    "ds_out_file = \"globalCoastalMorphodynamicsDb\"\n",
    "CF_dir = coclico_data_dir.joinpath(r\"CF\")  # directory to save output CF check files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d1359",
   "metadata": {},
   "source": [
    "### Check CF compliancy original NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open datasets\n",
    "ds = xr.open_dataset(ds_path)\n",
    "\n",
    "# check original dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check original CF compliancy\n",
    "\n",
    "check_compliancy(testfile=ds_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ae0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original CF compliancy\n",
    "save_compliancy(cap, testfile=ds_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9150b",
   "metadata": {},
   "source": [
    "### Make CF compliant alterations to the NetCDF files (dataset dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aebd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetCDF attribute alterations\n",
    "\n",
    "# rename global attribute names\n",
    "ds.attrs[\"Project_Acronym\"] = ds.attrs.pop(\"Project Acronym\")\n",
    "\n",
    "# add global attributes\n",
    "ds.attrs[\"Conventions\"] = \"CF-1.8\"\n",
    "\n",
    "# add or change certain variable / coordinate attributes\n",
    "ds.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "ds.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "ds.latland.attrs[\"units\"] = \"degrees_north\"\n",
    "ds.latsea.attrs[\"units\"] = \"degrees_north\"\n",
    "ds.firstlandlat.attrs[\"units\"] = \"degrees_north\"\n",
    "ds.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "ds.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "ds.lonland.attrs[\"units\"] = \"degrees_east\"\n",
    "ds.lonsea.attrs[\"units\"] = \"degrees_east\"\n",
    "ds.firstlandlon.attrs[\"units\"] = \"degrees_east\"\n",
    "ds.spuriousratio.attrs[\"units\"] = \"1\"\n",
    "ds.ptid.attrs[\"units\"] = \"1\"\n",
    "ds.landid.attrs[\"units\"] = \"1\"\n",
    "ds.landfound.attrs[\"units\"] = \"1\"\n",
    "ds.segmentid.attrs[\"units\"] = \"1\"\n",
    "ds.errorid.attrs[\"units\"] = \"1\"\n",
    "# ds.transect.attrs[\"units\"] = \"1\"\n",
    "ds.qualityflag.attrs[\"units\"] = \"1\"\n",
    "ds.firstYear.attrs[\"units\"] = \"yr\"\n",
    "ds.lastYear.attrs[\"units\"] = \"yr\"\n",
    "ds.transect.attrs[\"long_name\"] = \"number of stations\"\n",
    "ds.activezonetoland.attrs[\"long_name\"] = \"active zone to land\"\n",
    "ds.activezonetosea.attrs[\"long_name\"] = \"active zone to sea\"\n",
    "ds.landtoactivezone.attrs[\"long_name\"] = \"land to active zone\"\n",
    "ds.landtosea.attrs[\"long_name\"] = \"land to sea\"\n",
    "ds.ptid.attrs[\"long_name\"] = \"stations\"\n",
    "ds.landid.attrs[\"long_name\"] = \"country\"\n",
    "ds.errorid.attrs[\"long_name\"] = \"error id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41053533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetCDF variable and dimension alterations\n",
    "\n",
    "# rename or swap dimension names, the latter in case the name already exists as coordinate\n",
    "ds = ds.rename_dims({\"transect\": \"nstations\"})\n",
    "ds = ds.swap_dims({\"ntransect\": \"nstations\"})\n",
    "\n",
    "# rename variables, if necessary\n",
    "ds = ds.rename_vars(\n",
    "    {\n",
    "        \"transect\": \"nstations\",\n",
    "        \"latland\": \"lat_land\",\n",
    "        \"latsea\": \"lat_sea\",\n",
    "        \"lonland\": \"lon_land\",\n",
    "        \"lonsea\": \"lon_sea\",\n",
    "        \"activezonetoland\": \"active_zone_to_land\",\n",
    "        \"activezonetosea\": \"active_zone_to_sea\",\n",
    "        \"landtoactivezone\": \"land_to_active_zone\",\n",
    "        \"landtosea\": \"land_to_sea\",\n",
    "        \"seatoactivezone\": \"sea_to_active_zone\",\n",
    "        \"seatoland\": \"sea_to_land\",\n",
    "        \"spuriousratio\": \"spurious_ratio\",\n",
    "        \"ptid\": \"stations\",\n",
    "        \"landid\": \"country\",\n",
    "        \"firstlandlat\": \"first_land_lat\",\n",
    "        \"firstlandlon\": \"first_land_lon\",\n",
    "        \"landfound\": \"land_found\",\n",
    "        \"segmentid\": \"coastal_segment\",\n",
    "        \"errorid\": \"error_id\",\n",
    "        \"qualityflag\": \"quality_flag\",\n",
    "        \"firstYear\": \"first_year\",\n",
    "        \"lastYear\": \"last_year\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# set some data variables to coordinates to avoid duplication of dimensions in later stage\n",
    "ds = ds.set_coords(\n",
    "    [\n",
    "        \"lat\",\n",
    "        \"lat_land\",\n",
    "        \"lat_sea\",\n",
    "        \"lon\",\n",
    "        \"lon_land\",\n",
    "        \"lon_sea\",\n",
    "        \"stations\",\n",
    "        \"first_land_lon\",\n",
    "        \"first_land_lat\",\n",
    "        \"error_id\",\n",
    "        \"coastal_segment\",\n",
    "        \"quality_flag\",\n",
    "        \"spurious_ratio\",\n",
    "        \"country\",\n",
    "        \"land_found\",\n",
    "        \"first_year\",\n",
    "        \"last_year\",\n",
    "    ]\n",
    ")\n",
    "ds = ds.drop(\"nstations\")\n",
    "\n",
    "# add epsg\n",
    "ds.attrs[\"crs\"] = 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47662719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the xarray dataset, best practice is to have as many as possible bold dimensions (dimension == coordinate name).\n",
    "# in this way, the Front-End can access the variable directly without having to index the variable first\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new .nc files\n",
    "ds.to_netcdf(path=ds_dir.joinpath(ds_out_file + \"_CF.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7b37d",
   "metadata": {},
   "source": [
    "### Check CF compliancy altered NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb764dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check altered CF compliancy\n",
    "\n",
    "check_compliancy(testfile=ds_dir.joinpath(ds_out_file + \"_CF.nc\"), working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037decf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save altered CF compliancy\n",
    "save_compliancy(\n",
    "    cap, testfile=ds_dir.joinpath(ds_out_file + \"_CF.nc\"), working_dir=CF_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec081e",
   "metadata": {},
   "source": [
    "### write data to Zarr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba75d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to zarr in write mode (to overwrite if exists)\n",
    "ds.to_zarr(ds_dir.joinpath(\"%s.zarr\" % ds_out_file), mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d52b8dfbdab1c939c3c4b10b0d762f4c8139583e350f28e123ee37db8f80dd50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
